{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Installing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np  \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import cv2     #for image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor =[]\n",
    "path = './data/brain_tumor_dataset/yes/*.jpg'  #*jpg means all jpg files in the folder\n",
    "for f in glob.iglob(path):\n",
    "    img=cv2.imread(f)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    b,g,r = cv2.split(img)           # get b,g,r\n",
    "    cv2.merge([r,g,b],img)     # switch it to rgb\n",
    "    tumor.append(img)\n",
    "\n",
    "healthy =[]\n",
    "path = './data/brain_tumor_dataset/no/*.jpg'\n",
    "for f in glob.iglob(path):\n",
    "    img=cv2.imread(f)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    b,g,r = cv2.split(img)           # get b,g,r\n",
    "    cv2.merge([r,g,b],img)     # switch it to rgb\n",
    "    healthy.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy = np.array(healthy)\n",
    "tumor = np.array(tumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor.shape #154 images of 128x128 pixels with 3 channels (RGB)\n",
    "healthy.shape #98 images of 128x128 pixels with 3 channels (RGB)\n",
    "All=np.concatenate((tumor,healthy),axis=0) #concatenate the two arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245, 128, 128, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 91)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tumor), len(healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 180, 3)\n",
      "(360, 319, 3)\n",
      "(348, 287, 3)\n",
      "(336, 300, 3)\n",
      "(630, 587, 3)\n",
      "(993, 825, 3)\n",
      "(890, 700, 3)\n",
      "(246, 205, 3)\n",
      "(253, 200, 3)\n",
      "(512, 512, 3)\n",
      "(1200, 1059, 3)\n",
      "(279, 258, 3)\n",
      "(369, 400, 3)\n",
      "(324, 272, 3)\n",
      "(366, 310, 3)\n",
      "(312, 254, 3)\n",
      "(249, 178, 3)\n",
      "(298, 260, 3)\n",
      "(269, 249, 3)\n",
      "(310, 246, 3)\n",
      "(500, 377, 3)\n",
      "(245, 224, 3)\n",
      "(325, 254, 3)\n",
      "(300, 289, 3)\n",
      "(355, 311, 3)\n",
      "(352, 321, 3)\n",
      "(283, 231, 3)\n",
      "(380, 310, 3)\n",
      "(359, 300, 3)\n",
      "(431, 400, 3)\n",
      "(355, 310, 3)\n",
      "(370, 286, 3)\n",
      "(309, 232, 3)\n",
      "(334, 283, 3)\n",
      "(354, 303, 3)\n",
      "(360, 313, 3)\n",
      "(348, 297, 3)\n",
      "(351, 273, 3)\n",
      "(1200, 1059, 3)\n",
      "(316, 270, 3)\n",
      "(336, 264, 3)\n",
      "(303, 223, 3)\n",
      "(291, 253, 3)\n",
      "(350, 272, 3)\n",
      "(300, 263, 3)\n",
      "(325, 254, 3)\n",
      "(300, 289, 3)\n",
      "(355, 290, 3)\n",
      "(354, 279, 3)\n",
      "(586, 467, 3)\n",
      "(380, 310, 3)\n",
      "(318, 273, 3)\n",
      "(347, 300, 3)\n",
      "(173, 189, 3)\n",
      "(380, 318, 3)\n",
      "(450, 355, 3)\n",
      "(244, 206, 3)\n",
      "(879, 766, 3)\n",
      "(359, 297, 3)\n",
      "(342, 273, 3)\n",
      "(351, 262, 3)\n",
      "(256, 256, 3)\n",
      "(340, 314, 3)\n",
      "(212, 209, 3)\n",
      "(300, 240, 3)\n",
      "(247, 204, 3)\n",
      "(380, 294, 3)\n",
      "(277, 272, 3)\n",
      "(1024, 1024, 3)\n",
      "(344, 279, 3)\n",
      "(331, 272, 3)\n",
      "(351, 278, 3)\n",
      "(237, 213, 3)\n",
      "(355, 294, 3)\n",
      "(338, 248, 3)\n",
      "(315, 289, 3)\n",
      "(331, 260, 3)\n",
      "(630, 504, 3)\n",
      "(236, 213, 3)\n",
      "(349, 278, 3)\n",
      "(256, 197, 3)\n",
      "(338, 283, 3)\n",
      "(251, 201, 3)\n",
      "(295, 283, 3)\n",
      "(352, 281, 3)\n",
      "(960, 781, 3)\n",
      "(349, 292, 3)\n",
      "(324, 278, 3)\n",
      "(630, 628, 3)\n",
      "(630, 630, 3)\n",
      "(630, 630, 3)\n",
      "(630, 630, 3)\n",
      "(519, 456, 3)\n",
      "(325, 300, 3)\n",
      "(294, 250, 3)\n",
      "(555, 526, 3)\n",
      "(512, 512, 3)\n",
      "(380, 310, 3)\n",
      "(446, 450, 3)\n",
      "(251, 204, 3)\n",
      "(360, 319, 3)\n",
      "(325, 300, 3)\n",
      "(278, 236, 3)\n",
      "(225, 225, 3)\n",
      "(365, 306, 3)\n",
      "(1427, 1275, 3)\n",
      "(210, 200, 3)\n",
      "(337, 293, 3)\n",
      "(340, 291, 3)\n",
      "(929, 634, 3)\n",
      "(355, 320, 3)\n",
      "(307, 271, 3)\n",
      "(350, 315, 3)\n",
      "(938, 911, 3)\n",
      "(938, 911, 3)\n",
      "(219, 230, 3)\n",
      "(325, 300, 3)\n",
      "(620, 620, 3)\n",
      "(239, 211, 3)\n",
      "(340, 314, 3)\n",
      "(270, 229, 3)\n",
      "(938, 911, 3)\n",
      "(255, 197, 3)\n",
      "(520, 433, 3)\n",
      "(294, 250, 3)\n",
      "(243, 205, 3)\n",
      "(340, 288, 3)\n",
      "(233, 215, 3)\n",
      "(630, 504, 3)\n",
      "(456, 374, 3)\n",
      "(325, 300, 3)\n",
      "(349, 300, 3)\n",
      "(290, 250, 3)\n",
      "(620, 620, 3)\n",
      "(338, 264, 3)\n",
      "(442, 353, 3)\n",
      "(353, 300, 3)\n",
      "(251, 201, 3)\n",
      "(431, 400, 3)\n",
      "(446, 450, 3)\n",
      "(234, 216, 3)\n",
      "(223, 226, 3)\n",
      "(308, 244, 3)\n",
      "(350, 272, 3)\n",
      "(286, 241, 3)\n",
      "(630, 630, 3)\n",
      "(512, 512, 3)\n",
      "(1280, 1061, 3)\n",
      "(260, 194, 3)\n",
      "(225, 225, 3)\n",
      "(938, 864, 3)\n",
      "(355, 272, 3)\n",
      "(323, 276, 3)\n",
      "(357, 283, 3)\n"
     ]
    }
   ],
   "source": [
    "for img in tumor:\n",
    "    print(img.shape)  #all images are of different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preprocessing has to be done as dimensions are different"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
